{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256159db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this assignment I will load \"Managing Oneself, by Peter Druker\"ArithmeticError\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# ----------------------------------------------------\n",
    "#  PDF LOADER (Managing Oneself, by Peter Druker])\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def load_pdf_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads and loads a PDF from URL.\n",
    "    Returns full text (chunked and recombined).\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as tmp_file:\n",
    "        tmp_file.write(response.content)\n",
    "        tmp_pdf_path = tmp_file.name\n",
    "\n",
    "    loader = PyPDFLoader(tmp_pdf_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "\n",
    "    split_docs = splitter.split_documents(documents)\n",
    "\n",
    "    # Recombine into single string (context injected dynamically later)\n",
    "    full_text = \"\\n\\n\".join([doc.page_content for doc in split_docs])\n",
    "\n",
    "    return full_text\n",
    "\n",
    "# -----------------------------\n",
    "#  Usage\n",
    "# -----------------------------\n",
    "\n",
    "pdf_url = \"https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf\"\n",
    "article_text = load_pdf_from_url(pdf_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a. Author': 'Peter F. Drucker',\n",
      " 'b. Title': 'Managing Oneself',\n",
      " 'c. Relevance': 'This article is particularly relevant for AI professionals '\n",
      "                 'as it emphasizes the importance of self-awareness, strengths '\n",
      "                 'identification, and continuous personal development, all of '\n",
      "                 'which are essential in a rapidly evolving and competitive '\n",
      "                 'field like artificial intelligence. Understanding oneâ€™s '\n",
      "                 'strengths and performance modes can enhance collaboration '\n",
      "                 'within diverse teams, drive effective project management, '\n",
      "                 'and foster innovativeness.',\n",
      " 'd. Summary': 'In \"Managing Oneself,\" Peter F. Drucker posits that success in '\n",
      "               'the contemporary knowledge economy is contingent upon '\n",
      "               \"individuals' ability to manage their own careers proactively. \"\n",
      "               'With the prevailing shift in workplace dynamics, where '\n",
      "               'organizations no longer assume responsibility for career '\n",
      "               'trajectories, individuals are urged to act as their own chief '\n",
      "               'executive officers. Key to this self-management is an acute '\n",
      "               'awareness of personal strengths, weaknesses, work styles, and '\n",
      "               'values. Drucker introduces concepts such as feedback analysis '\n",
      "               'to discover strengths and identifies critical questions for '\n",
      "               'self-assessment, including how one learns, the type of work '\n",
      "               'environment that fosters productivity, and what personal '\n",
      "               'contributions can enhance organizational performance. He '\n",
      "               'elucidates the necessity for alignment between personal values '\n",
      "               'and organizational ethos, asserting that mismatches can lead '\n",
      "               'to frustration and ineffectiveness. Furthermore, Drucker '\n",
      "               'discusses the importance of managing interpersonal '\n",
      "               'relationships within the workplace and maintaining '\n",
      "               'responsibility for communication. The article culminates in '\n",
      "               'the notion that effective self-management incorporates a '\n",
      "               \"foresight for adapting one's career to encompass second paths \"\n",
      "               'or parallel undertakings as a means to sustain personal '\n",
      "               'fulfillment and professional relevance throughout prolonged '\n",
      "               'work lives. Thus, the ability to navigate oneâ€™s career '\n",
      "               'landscape thoughtfully is portrayed as both a necessity and an '\n",
      "               'opportunity in the modern workforce.',\n",
      " 'e. Tone': 'Formal Academic Writing',\n",
      " 'f. InputTokens': 1226,\n",
      " 'g. OutputTokens': 496}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "api_gateway_key = os.getenv('API_GATEWAY_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_gateway_key\n",
    "\n",
    "if not api_gateway_key:\n",
    "    raise ValueError(\"API_GATEWAY_KEY not found in Colab userdata\")\n",
    "\n",
    "\n",
    "\n",
    "class ArticleAnalysis(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "\n",
    "def get_result(result: ArticleAnalysis):\n",
    "    return {\n",
    "        \"a. Author\": result.Author,\n",
    "        \"b. Title\": result.Title,\n",
    "        \"c. Relevance\": result.Relevance,\n",
    "        \"d. Summary\": result.Summary,\n",
    "        \"e. Tone\": result.Tone,\n",
    "        \"f. InputTokens\": result.InputTokens,\n",
    "        \"g. OutputTokens\": result.OutputTokens,\n",
    "    }\n",
    "# ----\n",
    "\n",
    "def analyze_article(article_text: str) -> ArticleAnalysis:\n",
    "\n",
    "    #article_text = load_pdf_from_url(pdf_url)\n",
    "\n",
    "    developer_instructions = \"\"\"\n",
    "You are an expert AI research analyst.\n",
    "\n",
    "Your task:\n",
    "1. Extract the article title and author.\n",
    "2. Produce a concise summary (maximum 1000 tokens).\n",
    "3. Explain why this article is relevant for an AI professionalâ€™s professional development.\n",
    "4. Write the summary in Formal Academic Writing tone.\n",
    "5. Return structured output matching the required schema.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Below is the full article content:\n",
    "\n",
    "{article_text}\n",
    "\"\"\"\n",
    "\n",
    "    model =  init_chat_model(\"gpt-4o-mini\",\n",
    "                      model_provider=\"openai\",\n",
    "                      base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1',\n",
    "                      default_headers={\"x-api-key\": api_gateway_key},\n",
    "                      )\n",
    "\n",
    "\n",
    "    model_with_structure = model.with_structured_output(ArticleAnalysis)\n",
    "\n",
    "    response = model_with_structure.invoke(\n",
    "        developer_instructions + user_prompt\n",
    "    )\n",
    "    pprint(get_result(response))\n",
    "\n",
    "    return response\n",
    "\n",
    "# -----------------------------\n",
    "#  Usage\n",
    "# -----------------------------\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "result = analyze_article(article_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f601727f6e41b09f27cdaa83b81499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df19cc957f0478b828d6d54ecbf59e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49266e9e48284602bfce0c62d3b6a352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875286b2205d419a923a2dfea1faa541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SummarizationScore:** 0.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SummarizationReason:** The score is 0.00 because the summary includes a significant amount of extra information not present in the original text. This indicates a lack of alignment between the summary and the original content, leading to a poor summarization quality. The additional details about Peter F. Drucker's views, self-management, career management, and organizational roles suggest that the summary diverges considerably from the original text, failing to accurately represent its core message."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CoherenceScore:** 0.9042087731670373"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CoherenceReason:** The response demonstrates a logical flow of ideas, with each sentence building on the previous one. Transitions between concepts are smooth, particularly in the discussion of self-management and career adaptation. There are no ambiguous or unclear statements, and the sentence structure is clear, contributing to overall readability and comprehension. The only minor shortcoming is that the conclusion could be slightly more explicit in tying back to the initial premise, but this does not significantly detract from the overall coherence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TonalityScore:** 0.9201813212658987"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TonalityReason:** The response effectively reflects a formal academic style, avoiding casual or conversational phrases. It maintains objectivity and neutrality, presenting Drucker's ideas without personal bias. The lexical sophistication is high, with precise vocabulary and complex sentence structures. The tone is consistent throughout, aligning well with the evaluation steps. However, a slight deduction is made as the response could include more direct citations or references to enhance academic rigor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SafetyScore:** 0.9970687769513633"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SafetyReason:** The response aligns well with the evaluation steps. It contains no harmful or offensive language, and there are no biased or discriminatory statements. The information presented is accurate and not misleading, as it summarizes Peter F. Drucker's concepts on self-management. There is no unsafe professional advice given, and the communication is responsible, focusing on personal development and career management."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from pprint import pprint\n",
    "from deepeval import evaluate\n",
    "from deepeval.models import GPTModel\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "model = GPTModel(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    default_headers={\"x-api-key\": api_gateway_key},\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def print_evaluation_results(evaluation_results: dict):\n",
    "    \"\"\"\n",
    "    Display evaluation results stored in a dictionary in clean Markdown format.\n",
    "    \"\"\"\n",
    "    for key, value in evaluation_results.items():\n",
    "        display(Markdown(f\"**{key}:** {value}\"))\n",
    "\n",
    "\n",
    "def evaluate_summary(summary_text: str, article_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate a summary using DeepEval with:\n",
    "    - Summarization metric\n",
    "    - Coherence metric\n",
    "    - Tonality metric\n",
    "    - Safety metric\n",
    "\n",
    "    Returns structured dictionary output.\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Create Test Case\n",
    "    # -----------------------------\n",
    "    # Note:In the evaluation step, wIe construct the test case as :\n",
    "    test_case = LLMTestCase(\n",
    "        input= \"Evaluate the quality of this summary.\",\n",
    "        actual_output=summary_text,\n",
    "    )\n",
    "\n",
    "    #This is intentional to avoid context Re-Sending. Previously, \n",
    "    # the full article text was passed as the input to each evaluation metric. \n",
    "    # This significantly increased token usage and caused rate-limit (429) errors\n",
    "    # due to repeated large-context calls.\n",
    "\n",
    "    \n",
    "    # ============================================================\n",
    "    # Summarization Metric (Custom Questions)\n",
    "    # ============================================================\n",
    "\n",
    "    summarization_metric = SummarizationMetric(\n",
    "        model=model,\n",
    "        threshold=0.5,\n",
    "        assessment_questions=[\n",
    "            \"Does the summary accurately reflect the main argument of the article?\",\n",
    "            \"Does the summary capture the key supporting ideas?\",\n",
    "            \"Is the summary concise without omitting critical information?\",\n",
    "            \"Does the summary avoid introducing new information not in the article?\",\n",
    "            \"Is the summary logically structured and easy to follow?\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    summarization_metric.measure(test_case)\n",
    "\n",
    "    # ============================================================\n",
    "    # 2G-Eval: Coherence / Clarity\n",
    "    # ============================================================\n",
    "\n",
    "    coherence_metric = GEval(\n",
    "        model=model,\n",
    "        name=\"Coherence\",\n",
    "        criteria=\"Evaluate clarity, logical flow, and structural coherence.\",\n",
    "        evaluation_steps=[\n",
    "            \"Assess whether ideas flow logically from one sentence to another.\",\n",
    "            \"Determine whether transitions between concepts are smooth.\",\n",
    "            \"Check for ambiguous or unclear statements.\",\n",
    "            \"Evaluate sentence structure clarity.\",\n",
    "            \"Assess overall readability and comprehension.\"\n",
    "        ],\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    )\n",
    "\n",
    "    coherence_metric.measure(test_case)\n",
    "\n",
    "    # ============================================================\n",
    "    # G-Eval: Tonality\n",
    "    # ============================================================\n",
    "\n",
    "    tonality_metric = GEval(\n",
    "        model=model,\n",
    "        name=\"Tonality\",\n",
    "        criteria=\"Evaluate whether tone matches formal academic writing.\",\n",
    "        evaluation_steps=[\n",
    "            \"Determine if the language reflects formal academic style.\",\n",
    "            \"Check for absence of casual or conversational phrases.\",\n",
    "            \"Assess objectivity and neutrality.\",\n",
    "            \"Evaluate lexical sophistication.\",\n",
    "            \"Ensure consistent tone throughout.\"\n",
    "        ],\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    )\n",
    "\n",
    "    tonality_metric.measure(test_case)\n",
    "\n",
    "    # ============================================================\n",
    "    # G-Eval: Safety\n",
    "    # ============================================================\n",
    "\n",
    "    safety_metric = GEval(\n",
    "        model=model,\n",
    "        name=\"Safety\",\n",
    "        criteria=\"Evaluate safety and absence of harmful content.\",\n",
    "        evaluation_steps=[\n",
    "            \"Check for harmful or offensive language.\",\n",
    "            \"Ensure no biased or discriminatory statements.\",\n",
    "            \"Verify absence of misleading information.\",\n",
    "            \"Confirm no unsafe professional advice is given.\",\n",
    "            \"Assess overall responsible communication.\"\n",
    "        ],\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    )\n",
    "\n",
    "    safety_metric.measure(test_case)\n",
    "\n",
    "    # ============================================================\n",
    "    # Structured Output\n",
    "    # ============================================================\n",
    "\n",
    "    evaluation_results_dict = {\n",
    "        \"SummarizationScore\": summarization_metric.score,\n",
    "        \"SummarizationReason\": summarization_metric.reason,\n",
    "\n",
    "        \"CoherenceScore\": coherence_metric.score,\n",
    "        \"CoherenceReason\": coherence_metric.reason,\n",
    "\n",
    "        \"TonalityScore\": tonality_metric.score,\n",
    "        \"TonalityReason\": tonality_metric.reason,\n",
    "\n",
    "        \"SafetyScore\": safety_metric.score,\n",
    "        \"SafetyReason\": safety_metric.reason,\n",
    "        }\n",
    "\n",
    "    return evaluation_results_dict\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "#  Usage\n",
    "# -----------------------------\n",
    "#if __name__ == \"__main__\":\n",
    "evaluation_results = evaluate_summary(result.Summary, article_text)\n",
    "print_evaluation_results(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd49f4fcb6f045c5afc3452eb8ece567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfbb89cb14d40ef8e8d64c6d39f3334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe7f794ce5a4edaa72e1322105dac23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb18b39913243a4acb915c095dedef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**SummarizationScore:** 0.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SummarizationReason:** The score is 0.00 because the summary includes a significant amount of extra information not present in the original text. This indicates a lack of alignment between the summary and the original content, leading to a poor summarization quality. The additional details about Peter F. Drucker's views, self-management, career management, and organizational roles suggest that the summary diverges considerably from the original text, failing to accurately represent its core message."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CoherenceScore:** 0.9042087731670373"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CoherenceReason:** The response demonstrates a logical flow of ideas, with each sentence building on the previous one. Transitions between concepts are smooth, particularly in the discussion of self-management and career adaptation. There are no ambiguous or unclear statements, and the sentence structure is clear, contributing to overall readability and comprehension. The only minor shortcoming is that the conclusion could be slightly more explicit in tying back to the initial premise, but this does not significantly detract from the overall coherence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TonalityScore:** 0.9201813212658987"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TonalityReason:** The response effectively reflects a formal academic style, avoiding casual or conversational phrases. It maintains objectivity and neutrality, presenting Drucker's ideas without personal bias. The lexical sophistication is high, with precise vocabulary and complex sentence structures. The tone is consistent throughout, aligning well with the evaluation steps. However, a slight deduction is made as the response could include more direct citations or references to enhance academic rigor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SafetyScore:** 0.9970687769513633"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SafetyReason:** The response aligns well with the evaluation steps. It contains no harmful or offensive language, and there are no biased or discriminatory statements. The information presented is accurate and not misleading, as it summarizes Peter F. Drucker's concepts on self-management. There is no unsafe professional advice given, and the communication is responsible, focusing on personal development and career management."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Improved Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**SummarizationScore:** 0.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SummarizationReason:** The score is 0.00 because the summary includes a significant amount of extra information not present in the original text. This indicates a complete deviation from the original content, introducing concepts and references such as 'Managing Oneself,' Peter F. Drucker, and various self-management strategies that were not mentioned in the original text. The presence of these additional details without any basis in the original material results in a poor alignment between the summary and the source, justifying the lowest possible score."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CoherenceScore:** 0.9095349463613764"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**CoherenceReason:** The response demonstrates a logical flow of ideas, with each sentence building on the previous one. Transitions between concepts, such as the shift from self-management to feedback analysis, are smooth and well-articulated. There are no ambiguous or unclear statements, and the sentence structure is clear and concise. The overall readability and comprehension are high, effectively conveying Drucker's key points on career management."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TonalityScore:** 0.9222700128507461"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**TonalityReason:** The response reflects a formal academic style, with no casual or conversational phrases present. It maintains objectivity and neutrality, providing a clear summary of Drucker's ideas without personal bias. The lexical sophistication is high, using terms like 'proactive management,' 'feedback analysis,' and 'interpersonal relationships.' The tone is consistent throughout, focusing on the analytical presentation of Drucker's concepts. The only minor shortcoming is the lack of direct citations or references, which could enhance the academic rigor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SafetyScore:** 0.9966914021849649"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**SafetyReason:** The response aligns well with the evaluation steps. It contains no harmful or offensive language, biased or discriminatory statements, or misleading information. The summary of Drucker's work is accurate and provides responsible communication without offering unsafe professional advice. The focus on self-management and career development is presented thoughtfully and responsibly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#            -------------------------------------\n",
    "#               Creating  an Enhancement Prompt\n",
    "#            -------------------------------------\n",
    "\n",
    "# Note: To reduce the risk of the system validating its own weaknesses,\n",
    "#       I intentionally use gpt-4o-mini for generation tasks \n",
    "#       analyze_article and enhance_summary) and gpt-4o for evaluation.\n",
    "\n",
    "def enhance_summary(article_text: str, original_summary: str, evaluation_results: dict):\n",
    "    \"\"\"\n",
    "    Uses evaluation feedback to improve the summary.\n",
    "    \"\"\"\n",
    "\n",
    "    enhancement_prompt = f\"\"\"\n",
    "You are an expert academic editor.\n",
    "\n",
    "Below is the ORIGINAL ARTICLE:\n",
    "{article_text}\n",
    "\n",
    "Below is the CURRENT SUMMARY:\n",
    "{original_summary}\n",
    "\n",
    "Below is the EVALUATION FEEDBACK:\n",
    "{evaluation_results}\n",
    "\n",
    "TASK:\n",
    "Improve the summary by addressing ALL weaknesses mentioned in the evaluation.\n",
    "\n",
    "STRICT REQUIREMENTS:\n",
    "- Maintain Formal Academic Writing tone.\n",
    "- Remain concise.\n",
    "- Do NOT introduce new information.\n",
    "- Improve clarity and logical flow.\n",
    "- Strengthen alignment with the article's main argument.\n",
    "- Keep under 1000 tokens.\n",
    "\n",
    "Return ONLY the improved summary.\n",
    "\"\"\"\n",
    "\n",
    "    model = init_chat_model(\n",
    "        \"gpt-4o-mini\",\n",
    "        model_provider=\"openai\",\n",
    "        base_url=\"https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\",\n",
    "        default_headers={\"x-api-key\": api_gateway_key},\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    response = model.invoke(enhancement_prompt)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def self_correcting_pipeline(article_text: str, original_summary: str, evaluation_results: dict):\n",
    "\n",
    "\n",
    "#                 -------------------------------\n",
    "#                   Gemerating Improved Summary\n",
    "#                 -------------------------------\n",
    "\n",
    "    improved_summary = enhance_summary(\n",
    "        article_text,\n",
    "        result.Summary,\n",
    "        evaluation_results\n",
    "    )\n",
    "\n",
    "#                ---------------------------------------\n",
    "#                     Re-evaluating  Improved Summary\n",
    "#                ---------------------------------------\n",
    "\n",
    "    improved_evaluation = evaluate_summary(improved_summary, article_text)\n",
    "    #pprint(improved_evaluation)\n",
    "\n",
    "#                 -----------------------\n",
    "#                    Compare Results\n",
    "#                 -----------------------\n",
    "    print(\"Original Evaluation:\")\n",
    "    print_evaluation_results(evaluation_results)\n",
    "\n",
    "    print(\"\\nImproved Evaluation:\")\n",
    "    print_evaluation_results(improved_evaluation)\n",
    "\n",
    "    return improved_summary\n",
    "\n",
    "# -----------------------------\n",
    "#  Usage\n",
    "# -----------------------------\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "improved_summary = self_correcting_pipeline(\n",
    "        article_text,\n",
    "        result.Summary,\n",
    "        evaluation_results\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
